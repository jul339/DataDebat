{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666c5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connexion établie avec Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "# remonte jusqu’à la racine du repo à partir du notebook\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "from src.db.es_connection import ESConnection\n",
    "\n",
    "# Connexion locale\n",
    "es = ESConnection(\"http://localhost:9200\")\n",
    "\n",
    "# Vérifier la connexion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b7746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n"
     ]
    }
   ],
   "source": [
    "print(es.get_word_count(2769637))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c1f83",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Erreur lors du comptage des mots pour 2022/01/03: BadRequestError(400, 'search_phase_execution_exception', 'failed to parse date field [2022/01/03] with format [yyyy-MM-dd]: [failed to parse date field [2022/01/03] with format [yyyy-MM-dd]]')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDebat/src/db/es_connection.py:214\u001b[39m, in \u001b[36mESConnection.get_word_count_for_year\u001b[39m\u001b[34m(self, date_seance, field)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mes\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mterm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate_seance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_seance\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword_count\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscript\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m    223\u001b[39m \u001b[33;43m                            def src = params._source;\u001b[39;49m\n\u001b[32m    224\u001b[39m \u001b[33;43m                            if (src == null || !src.containsKey(params.field)) return 0;\u001b[39;49m\n\u001b[32m    225\u001b[39m \u001b[33;43m                            def txt = src[params.field];\u001b[39;49m\n\u001b[32m    226\u001b[39m \u001b[33;43m                            if (txt == null) return 0;\u001b[39;49m\n\u001b[32m    227\u001b[39m \u001b[33;43m                            return txt.toString().splitOnToken(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m).length;\u001b[39;49m\n\u001b[32m    228\u001b[39m \u001b[33;43m                        \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfield\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/datadebat/lib/python3.11/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[39m, in \u001b[36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/datadebat/lib/python3.11/site-packages/elasticsearch/_sync/client/__init__.py:3924\u001b[39m, in \u001b[36mElasticsearch.search\u001b[39m\u001b[34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version)\u001b[39m\n\u001b[32m   3923\u001b[39m     __headers[\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m3924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   3925\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__body\u001b[49m\n\u001b[32m   3926\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/datadebat/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[39m, in \u001b[36mBaseClient.perform_request\u001b[39m\u001b[34m(self, method, path, params, headers, body)\u001b[39m\n\u001b[32m    318\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS.get(meta.status, ApiError)(\n\u001b[32m    321\u001b[39m         message=message, meta=meta, body=resp_body\n\u001b[32m    322\u001b[39m     )\n\u001b[32m    324\u001b[39m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n",
      "\u001b[31mBadRequestError\u001b[39m: BadRequestError(400, 'search_phase_execution_exception', 'failed to parse date field [2022/01/03] with format [yyyy-MM-dd]: [failed to parse date field [2022/01/03] with format [yyyy-MM-dd]]')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_word_count_for_year\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2022/01/03\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataDebat/src/db/es_connection.py:236\u001b[39m, in \u001b[36mESConnection.get_word_count_for_year\u001b[39m\u001b[34m(self, date_seance, field)\u001b[39m\n\u001b[32m    214\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.es.search(\n\u001b[32m    215\u001b[39m         index=\u001b[38;5;28mself\u001b[39m.index_name,\n\u001b[32m    216\u001b[39m         size=\u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m         },\n\u001b[32m    234\u001b[39m     )\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mErreur lors du comptage des mots pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_seance\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(response.get(\u001b[33m\"\u001b[39m\u001b[33maggregations\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mword_count\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: Erreur lors du comptage des mots pour 2022/01/03: BadRequestError(400, 'search_phase_execution_exception', 'failed to parse date field [2022/01/03] with format [yyyy-MM-dd]: [failed to parse date field [2022/01/03] with format [yyyy-MM-dd]]')"
     ]
    }
   ],
   "source": [
    "es.get_word_count_for_year('2022-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "# import io\n",
    "# from lxml import etree\n",
    "\n",
    "# nom_fichier_taz = \"../data/raw/AN_2022001.taz\"\n",
    "\n",
    "# with tarfile.open(nom_fichier_taz, \"r:*\") as taz:\n",
    "#     membre_tar = next(m for m in taz.getmembers() if m.name.endswith(\".tar\"))\n",
    "#     tar_bytes = taz.extractfile(membre_tar).read()\n",
    "#     tar_buffer = io.BytesIO(tar_bytes)\n",
    "\n",
    "#     with tarfile.open(fileobj=tar_buffer, mode=\"r:\") as tar:\n",
    "#         for membre in tar.getmembers():\n",
    "#             if membre.name.endswith(\".xml\"):\n",
    "#                 f = tar.extractfile(membre)\n",
    "#                 if f is None:\n",
    "#                     continue\n",
    "\n",
    "#                 xml_bytes = f.read()\n",
    "#                 root = etree.fromstring(xml_bytes)\n",
    "\n",
    "#                 contenu = root.find(\".//ContenuDANBleu\")\n",
    "#                 if contenu is None:\n",
    "#                     contenu = root.find(\".//ContenuDANBlanc\")\n",
    "\n",
    "#                 if contenu is None:\n",
    "#                     continue\n",
    "\n",
    "#                 print(len(contenu.xpath(\".//intervention\")), \"interventions dans\", membre.name)\n",
    "#                 for inter in contenu.xpath(\".//intervention\"):\n",
    "#                     orateur = inter.xpath(\".//orateur/@nom\")\n",
    "#                     groupe = inter.xpath(\".//orateur/@groupe\")\n",
    "#                     texte = \" \".join(inter.xpath(\".//texte//text()\"))\n",
    "\n",
    "#                     doc = {\n",
    "#                         \"fichier_xml\": membre.name,\n",
    "#                         \"orateur\": orateur[0] if orateur else None,\n",
    "#                         \"groupe\": groupe[0] if groupe else None,\n",
    "#                         \"texte\": texte\n",
    "#                     }\n",
    "\n",
    "#                     # Envoyer dans Elasticsearch\n",
    "#                     res = es.index(index=\"deputes_interventions\", document=doc)\n",
    "#                     print(f\"Document indexé : {res['_id']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datadebat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
